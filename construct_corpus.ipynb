{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e51a1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cefa8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_path = \"/ssddata/jimmy/temporalRAG/FNSPID/data_final_25/corpus/year_interval_selected_data_25stock.csv\"\n",
    "real_news = pd.read_csv(real_news_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "327bcf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Url</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author</th>\n",
       "      <th>Article</th>\n",
       "      <th>Lsa_summary</th>\n",
       "      <th>Luhn_summary</th>\n",
       "      <th>Textrank_summary</th>\n",
       "      <th>Lexrank_summary</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97378</td>\n",
       "      <td>97378.0</td>\n",
       "      <td>2022-12-15 00:00:00 UTC</td>\n",
       "      <td>The 3 Best ETFs to Buy for 2023</td>\n",
       "      <td>AGG</td>\n",
       "      <td>https://www.nasdaq.com/articles/the-3-best-etf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>InvestorPlace - Stock Market News, Stock Advic...</td>\n",
       "      <td>This portfolio style is more popular within th...</td>\n",
       "      <td>This portfolio style is more popular within th...</td>\n",
       "      <td>This portfolio style is more popular within th...</td>\n",
       "      <td>This portfolio style is more popular within th...</td>\n",
       "      <td>97378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97383</td>\n",
       "      <td>97383.0</td>\n",
       "      <td>2022-12-02 00:00:00 UTC</td>\n",
       "      <td>3 ETFs That Are All You Need for Retirement</td>\n",
       "      <td>AGG</td>\n",
       "      <td>https://www.nasdaq.com/articles/3-etfs-that-ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diversification is essential to your success a...</td>\n",
       "      <td>Aggregate Bond ETF Rising interest rates have ...</td>\n",
       "      <td>Aggregate Bond ETF Rising interest rates have ...</td>\n",
       "      <td>Aggregate Bond ETF Rising interest rates have ...</td>\n",
       "      <td>Aggregate Bond ETF Rising interest rates have ...</td>\n",
       "      <td>97383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97386</td>\n",
       "      <td>97386.0</td>\n",
       "      <td>2022-11-16 00:00:00 UTC</td>\n",
       "      <td>Todd Rosenbluth Gets Active on Yahoo Finance</td>\n",
       "      <td>AGG</td>\n",
       "      <td>https://www.nasdaq.com/articles/todd-rosenblut...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VettaFi's head of research Todd Rosenbluth got...</td>\n",
       "      <td>Aggregate Bond ETF (AGG). VettaFi's head of re...</td>\n",
       "      <td>Aggregate Bond ETF (AGG). VettaFi's head of re...</td>\n",
       "      <td>Aggregate Bond ETF (AGG). VettaFi's head of re...</td>\n",
       "      <td>Aggregate Bond ETF (AGG). VettaFi's head of re...</td>\n",
       "      <td>97386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97387</td>\n",
       "      <td>97387.0</td>\n",
       "      <td>2022-11-14 00:00:00 UTC</td>\n",
       "      <td>Don’t Get AGG-ravated, Expand Your Fixed Incom...</td>\n",
       "      <td>AGG</td>\n",
       "      <td>https://www.nasdaq.com/articles/dont-get-agg-r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While 2022 is not finished, two things are qui...</td>\n",
       "      <td>The following strategies are worthy of conside...</td>\n",
       "      <td>Actively-Managed Core Fixed Income ETFs The Fi...</td>\n",
       "      <td>Actively-Managed Core Fixed Income ETFs The Fi...</td>\n",
       "      <td>Actively-Managed Core Fixed Income ETFs The Fi...</td>\n",
       "      <td>97387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97392</td>\n",
       "      <td>97392.0</td>\n",
       "      <td>2022-09-28 00:00:00 UTC</td>\n",
       "      <td>The 10-Year Treasury Yield Just Topped 4%: Wha...</td>\n",
       "      <td>AGG</td>\n",
       "      <td>https://www.nasdaq.com/articles/the-10-year-tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bear market in stocks has made portfolio v...</td>\n",
       "      <td>Inflation has prompted the Federal Reserve to ...</td>\n",
       "      <td>Aggregate Bond (NYSEMKT: AGG) and Vanguard Tot...</td>\n",
       "      <td>Inflation has prompted the Federal Reserve to ...</td>\n",
       "      <td>Inflation has prompted the Federal Reserve to ...</td>\n",
       "      <td>97392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                     Date  \\\n",
       "0         97378     97378.0  2022-12-15 00:00:00 UTC   \n",
       "1         97383     97383.0  2022-12-02 00:00:00 UTC   \n",
       "2         97386     97386.0  2022-11-16 00:00:00 UTC   \n",
       "3         97387     97387.0  2022-11-14 00:00:00 UTC   \n",
       "4         97392     97392.0  2022-09-28 00:00:00 UTC   \n",
       "\n",
       "                                       Article_title Stock_symbol  \\\n",
       "0                    The 3 Best ETFs to Buy for 2023          AGG   \n",
       "1        3 ETFs That Are All You Need for Retirement          AGG   \n",
       "2       Todd Rosenbluth Gets Active on Yahoo Finance          AGG   \n",
       "3  Don’t Get AGG-ravated, Expand Your Fixed Incom...          AGG   \n",
       "4  The 10-Year Treasury Yield Just Topped 4%: Wha...          AGG   \n",
       "\n",
       "                                                 Url  Publisher  Author  \\\n",
       "0  https://www.nasdaq.com/articles/the-3-best-etf...        NaN     NaN   \n",
       "1  https://www.nasdaq.com/articles/3-etfs-that-ar...        NaN     NaN   \n",
       "2  https://www.nasdaq.com/articles/todd-rosenblut...        NaN     NaN   \n",
       "3  https://www.nasdaq.com/articles/dont-get-agg-r...        NaN     NaN   \n",
       "4  https://www.nasdaq.com/articles/the-10-year-tr...        NaN     NaN   \n",
       "\n",
       "                                             Article  \\\n",
       "0  InvestorPlace - Stock Market News, Stock Advic...   \n",
       "1  Diversification is essential to your success a...   \n",
       "2  VettaFi's head of research Todd Rosenbluth got...   \n",
       "3  While 2022 is not finished, two things are qui...   \n",
       "4  The bear market in stocks has made portfolio v...   \n",
       "\n",
       "                                         Lsa_summary  \\\n",
       "0  This portfolio style is more popular within th...   \n",
       "1  Aggregate Bond ETF Rising interest rates have ...   \n",
       "2  Aggregate Bond ETF (AGG). VettaFi's head of re...   \n",
       "3  The following strategies are worthy of conside...   \n",
       "4  Inflation has prompted the Federal Reserve to ...   \n",
       "\n",
       "                                        Luhn_summary  \\\n",
       "0  This portfolio style is more popular within th...   \n",
       "1  Aggregate Bond ETF Rising interest rates have ...   \n",
       "2  Aggregate Bond ETF (AGG). VettaFi's head of re...   \n",
       "3  Actively-Managed Core Fixed Income ETFs The Fi...   \n",
       "4  Aggregate Bond (NYSEMKT: AGG) and Vanguard Tot...   \n",
       "\n",
       "                                    Textrank_summary  \\\n",
       "0  This portfolio style is more popular within th...   \n",
       "1  Aggregate Bond ETF Rising interest rates have ...   \n",
       "2  Aggregate Bond ETF (AGG). VettaFi's head of re...   \n",
       "3  Actively-Managed Core Fixed Income ETFs The Fi...   \n",
       "4  Inflation has prompted the Federal Reserve to ...   \n",
       "\n",
       "                                     Lexrank_summary  unique_id  \n",
       "0  This portfolio style is more popular within th...      97378  \n",
       "1  Aggregate Bond ETF Rising interest rates have ...      97383  \n",
       "2  Aggregate Bond ETF (AGG). VettaFi's head of re...      97386  \n",
       "3  Actively-Managed Core Fixed Income ETFs The Fi...      97387  \n",
       "4  Inflation has prompted the Federal Reserve to ...      97392  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c50d29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import os\n",
    "\n",
    "def get_end_of_month_date(month_year_str):\n",
    "    \"\"\"\n",
    "    Converts a 'Month YYYY' string (e.g., 'January 2012') to an \n",
    "    end-of-month date string in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the month and year\n",
    "        dt_obj = datetime.strptime(month_year_str, '%B %Y')\n",
    "        # Get the last day of the month\n",
    "        last_day = calendar.monthrange(dt_obj.year, dt_obj.month)[1]\n",
    "        # Create a new datetime object for the end of the month\n",
    "        end_of_month_dt = datetime(dt_obj.year, dt_obj.month, last_day)\n",
    "        return end_of_month_dt.strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing month_year_str '{month_year_str}': {e}\")\n",
    "        # Fallback or raise error, here returning None or a default\n",
    "        return None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "398f81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_csv_path = real_news_path\n",
    "output_dir = \"/home/jimmy/Time-Aware_RAG/DQABench\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1447fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing real news from: /ssddata/jimmy/temporalRAG/FNSPID/data_final_25/corpus/year_interval_selected_data_25stock.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 23737 real news articles.\n"
     ]
    }
   ],
   "source": [
    "c_final_data = []\n",
    "real_metadata_list = []\n",
    "synth_metadata_list = []\n",
    "global_doc_id_counter = 1\n",
    "\n",
    "# --- Process Real News ---\n",
    "print(f\"Processing real news from: {real_news_csv_path}\")\n",
    "try:\n",
    "    df_real = pd.read_csv(real_news_csv_path)\n",
    "    for _, row in df_real.iterrows():\n",
    "        original_id = str(row['unique_id']) # Assuming 'unique_id' is the original ID\n",
    "        \n",
    "        # Attempt to parse the date and format it\n",
    "        try:\n",
    "            original_publish_date_dt = pd.to_datetime(row['Date'])\n",
    "            original_publish_date_str = original_publish_date_dt.strftime('%Y-%m-%d')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not parse date '{row['Date']}' for real news ID {original_id}. Error: {e}. Storing as is or skipping.\")\n",
    "            original_publish_date_str = str(row['Date']) # Store as is, or handle error appropriately\n",
    "\n",
    "        article_text = str(row['Article'])\n",
    "        article_title = str(row['Article_title']) # Keep title if needed, maybe prepend to article\n",
    "\n",
    "        # You might want to combine title and article, e.g.:\n",
    "        combined_text = f\"Title:{article_title}\\n{article_text}\"\n",
    "\n",
    "        global_id = f\"doc_{global_doc_id_counter:05d}\"\n",
    "\n",
    "        real_metadata_list.append({\n",
    "            'global_id': global_id,\n",
    "            'original_id': original_id,\n",
    "            'publish_date': original_publish_date_str\n",
    "        })\n",
    "\n",
    "        c_final_data.append({\n",
    "            'id': global_id,\n",
    "            'text': combined_text, # or combined_text\n",
    "            'source_type': 'real'\n",
    "        })\n",
    "        global_doc_id_counter += 1\n",
    "    print(f\"Processed {len(df_real)} real news articles.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Real news CSV file not found at {real_news_csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing real news: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e9c084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_news_json_path = \"/ssddata/jimmy/temporalRAG/FNSPID/data_final_25/corpus/generated_financial_new_v2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00a13527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing synthetic news from: /ssddata/jimmy/temporalRAG/FNSPID/data_final_25/corpus/generated_financial_new_v2.json\n",
      "Processed 3300 synthetic news articles.\n",
      "\n",
      "Writing C_final.jsonl to: /home/jimmy/Time-Aware_RAG/DQABench/C_final.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 27037 articles to C_final.jsonl\n",
      "\n",
      "Writing C_real_metadata.csv to: /home/jimmy/Time-Aware_RAG/DQABench_internalCheck/C_real_metadata.csv\n",
      "Successfully wrote 23737 real news metadata entries.\n",
      "\n",
      "Writing C_synth_metadata.csv to: /home/jimmy/Time-Aware_RAG/DQABench_internalCheck/C_synth_metadata.csv\n",
      "Successfully wrote 3300 synthetic news metadata entries.\n",
      "\n",
      "Corpus processing complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Process Synthetic News ---\n",
    "print(f\"\\nProcessing synthetic news from: {synth_news_json_path}\")\n",
    "try:\n",
    "    with open(synth_news_json_path, 'r', encoding='utf-8') as f:\n",
    "        synth_news_list = json.load(f)\n",
    "    \n",
    "    for item in synth_news_list:\n",
    "        original_id = str(item['unique_id']) # UUID\n",
    "        target_month_year = str(item['month_year'])\n",
    "        article_text = str(item['article'])\n",
    "\n",
    "        derived_publish_date = get_end_of_month_date(target_month_year)\n",
    "        if derived_publish_date is None:\n",
    "            print(f\"Warning: Could not derive publish date for synthetic news ID {original_id} with month_year '{target_month_year}'. Skipping this item or using placeholder.\")\n",
    "            # Decide how to handle: skip, use a placeholder, or raise an error\n",
    "            derived_publish_date = \"N/A\" # Example placeholder\n",
    "\n",
    "        global_id = f\"doc_{global_doc_id_counter:05d}\"\n",
    "\n",
    "        synth_metadata_list.append({\n",
    "            'global_id': global_id,\n",
    "            'original_id': original_id,\n",
    "            'target_month_year': target_month_year,\n",
    "            'derived_publish_date': derived_publish_date\n",
    "        })\n",
    "\n",
    "        c_final_data.append({\n",
    "            'id': global_id,\n",
    "            'text': article_text,\n",
    "            'source_type': 'synthetic'\n",
    "        })\n",
    "        global_doc_id_counter += 1\n",
    "    print(f\"Processed {len(synth_news_list)} synthetic news articles.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Synthetic news JSON file not found at {synth_news_json_path}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from {synth_news_json_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing synthetic news: {e}\")\n",
    "\n",
    "# --- Create output directory if it doesn't exist ---\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"\\nCreated output directory: {output_dir}\")\n",
    "\n",
    "# --- Write C_final.jsonl ---\n",
    "c_final_path = os.path.join(output_dir, 'C_final.jsonl')\n",
    "print(f\"\\nWriting C_final.jsonl to: {c_final_path}\")\n",
    "try:\n",
    "    with open(c_final_path, 'w', encoding='utf-8') as f:\n",
    "        for entry in c_final_data:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "    print(f\"Successfully wrote {len(c_final_data)} articles to C_final.jsonl\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing C_final.jsonl: {e}\")\n",
    "\n",
    "# --- Write C_real_metadata.csv ---\n",
    "if real_metadata_list:\n",
    "    df_real_meta = pd.DataFrame(real_metadata_list)\n",
    "    real_meta_path = os.path.join(\"/home/jimmy/Time-Aware_RAG/DQABench_internalCheck\", 'C_real_metadata.csv')\n",
    "    print(f\"\\nWriting C_real_metadata.csv to: {real_meta_path}\")\n",
    "    try:\n",
    "        df_real_meta.to_csv(real_meta_path, index=False, quoting=1) # quoting=1 is csv.QUOTE_ALL\n",
    "        print(f\"Successfully wrote {len(df_real_meta)} real news metadata entries.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing C_real_metadata.csv: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo real news metadata to write.\")\n",
    "\n",
    "\n",
    "if synth_metadata_list:\n",
    "    df_synth_meta = pd.DataFrame(synth_metadata_list)\n",
    "    synth_meta_path = os.path.join(\"/home/jimmy/Time-Aware_RAG/DQABench_internalCheck\", 'C_synth_metadata.csv')\n",
    "    print(f\"\\nWriting C_synth_metadata.csv to: {synth_meta_path}\")\n",
    "    try:\n",
    "        df_synth_meta.to_csv(synth_meta_path, index=False, quoting=1)\n",
    "        print(f\"Successfully wrote {len(df_synth_meta)} synthetic news metadata entries.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing C_synth_metadata.csv: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo synthetic news metadata to write.\")\n",
    "    \n",
    "print(\"\\nCorpus processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e122eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing C_real_metadata.csv to: /home/jimmy/Time-Aware_RAG/DQABench/external_metadata/C_real_metadata.csv\n",
      "Successfully wrote 23737 real news metadata entries.\n"
     ]
    }
   ],
   "source": [
    "# real_metadata_list_clean be the copy of real_metadata_list without \"original_id\" \n",
    "real_metadata_list_clean = []\n",
    "for item in real_metadata_list:\n",
    "    # Create a new dictionary without the 'original_id' key\n",
    "    cleaned_item = {k: v for k, v in item.items() if k != 'original_id'}\n",
    "    real_metadata_list_clean.append(cleaned_item)\n",
    "\n",
    "if real_metadata_list_clean:\n",
    "    df_real_meta = pd.DataFrame(real_metadata_list_clean)\n",
    "    real_meta_path = os.path.join(\"/home/jimmy/Time-Aware_RAG/DQABench/external_metadata\", 'C_real_metadata.csv')\n",
    "    print(f\"\\nWriting C_real_metadata.csv to: {real_meta_path}\")\n",
    "    try:\n",
    "        df_real_meta.to_csv(real_meta_path, index=False, quoting=1) # quoting=1 is csv.QUOTE_ALL\n",
    "        print(f\"Successfully wrote {len(df_real_meta)} real news metadata entries.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing C_real_metadata.csv: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo real news metadata to write.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dbbfb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing C_synth_metadata.csv to: /home/jimmy/Time-Aware_RAG/DQABench/external_metadata/C_synth_metadata.csv\n",
      "Successfully wrote 3300 synthetic news metadata entries.\n",
      "\n",
      "Corpus processing complete.\n"
     ]
    }
   ],
   "source": [
    "synth_metadata_list_clean = []\n",
    "for item in synth_metadata_list:\n",
    "    # Create a new dictionary without the 'original_id' key\n",
    "    cleaned_item = {k: v for k, v in item.items() if k != 'original_id' and k != 'target_month_year'}\n",
    "    synth_metadata_list_clean.append(cleaned_item)\n",
    "\n",
    "if synth_metadata_list_clean:\n",
    "    df_synth_meta = pd.DataFrame(synth_metadata_list_clean)\n",
    "    synth_meta_path = os.path.join(\"/home/jimmy/Time-Aware_RAG/DQABench/external_metadata\", 'C_synth_metadata.csv')\n",
    "    print(f\"\\nWriting C_synth_metadata.csv to: {synth_meta_path}\")\n",
    "    try:\n",
    "        df_synth_meta.to_csv(synth_meta_path, index=False, quoting=1)\n",
    "        print(f\"Successfully wrote {len(df_synth_meta)} synthetic news metadata entries.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing C_synth_metadata.csv: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo synthetic news metadata to write.\")\n",
    "    \n",
    "print(\"\\nCorpus processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10558c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {}\n",
    "\n",
    "for item in real_metadata_list:\n",
    "    id_dict[item['original_id']] = item['global_id']\n",
    "\n",
    "for item in synth_metadata_list:\n",
    "    id_dict[item['original_id']] = item['global_id']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bca4c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27037"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f23bbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/ssddata/jimmy/temporalRAG/FNSPID/data_final_25/kb_data/corpus_combine.json\", \"r\") as file:\n",
    "    chunk_data = json.load(file)\n",
    "\n",
    "chunk_data_output = []\n",
    "\n",
    "for data in chunk_data:\n",
    "    if data['uid'] in id_dict:\n",
    "        data['corpus_id'] = id_dict[data['uid']]\n",
    "        # data['chunk_uid'] = data[\"corpus_uid\"]\n",
    "        del data[\"corpus_uid\"]\n",
    "        chunk_data_output.append(data)\n",
    "    else:\n",
    "        print(f\"ID {data['id']} not found in id_dict.\")\n",
    "\n",
    "with open(\"/home/jimmy/Time-Aware_RAG/experiment/extracted_time_interval.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(chunk_data_output, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f634f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporalRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
